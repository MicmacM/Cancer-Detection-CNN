{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e17921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ambarish/breakhis?dataset_version_number=4&file_name=Folds.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120k/120k [00:00<00:00, 632kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting zip of Folds.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:    fold  mag    grp                                           filename\n",
      "0     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...\n",
      "1     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...\n",
      "2     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...\n",
      "3     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...\n",
      "4     1  100  train  BreaKHis_v1/histology_slides/breast/benign/SOB...\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"Folds.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"ambarish/breakhis\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d26b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset  # Ensure Dataset is imported\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import cv2\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2428ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-009.png\n",
      "data/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-008.png\n",
      "data/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-003.png\n",
      "data/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-002.png\n",
      "data/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-014.png\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "breast_img_paths = glob.glob('data/**/*.png', recursive = True)\n",
    "for img_path in breast_img_paths[:5]:\n",
    "    print(img_path)\n",
    "    img_name = Path(img_path).name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8593282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of cancer\n",
    "benign = []\n",
    "malignant = []\n",
    "# subtypes\n",
    "A, F, PT, TA = [], [], [], [] # subtypes for benign\n",
    "DC, LC, MC, PC = [], [], [], [] # subtypes for malignant\n",
    "\n",
    "for img in breast_img_paths:\n",
    "    img_name = Path(img).name\n",
    "    if img_name[6] == 'A':\n",
    "        A.append(img)\n",
    "    elif img_name[6] == 'F':\n",
    "        F.append(img)\n",
    "    elif img_name[6] == 'P'and img_name[7] == 'T':\n",
    "        PT.append(img)\n",
    "    elif img_name[6] == 'T':\n",
    "        TA.append(img)\n",
    "    elif img_name[6] == 'D':\n",
    "        DC.append(img)\n",
    "    elif img_name[6] == 'L':\n",
    "        LC.append(img)\n",
    "    elif img_name[6] == 'M':\n",
    "        MC.append(img)\n",
    "    elif img_name[6] == 'P':\n",
    "        PC.append(img)\n",
    "    \n",
    "    if img_name[4] == 'B':\n",
    "        benign.append(img)\n",
    "    else:\n",
    "        malignant.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ef5953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-011.png', 'data/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-005.png', 'data/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-004.png', 'data/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-010.png', 'data/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-006.png']\n",
      "5429\n"
     ]
    }
   ],
   "source": [
    "print(benign[:5])\n",
    "print(len(malignant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0fb17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreakHisDataset(Dataset):\n",
    "    def __init__(self, data_folder_path, labels_path = \"Folds.csv\", magnification = [40], transform=None, train=True):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "        self.magnification = magnification\n",
    "        self.train = train\n",
    "\n",
    "        self._load_data()\n",
    "        target_split = 0 if self.train else 1\n",
    "        self.data = self.data[self.data[:, 2].astype(int) == target_split]\n",
    "\n",
    "    def _load_data(self):\n",
    "        # Load all image path\n",
    "        breast_img_paths = glob.glob(self.data_folder_path + '/**/*.png', recursive = True)\n",
    "        # Keep only the ones with selected magnification\n",
    "        filtered_img_paths = []\n",
    "        for img in breast_img_paths:\n",
    "            img_name = Path(img).name\n",
    "            for mag in self.magnification:\n",
    "                if f\"-{mag}-\" in img_name:\n",
    "                    filtered_img_paths.append(img) \n",
    "        triplets = []\n",
    "\n",
    "        df = pd.read_csv(self.labels_path)\n",
    "        for image_path in filtered_img_paths:\n",
    "            filename = Path(image_path).name\n",
    "            row = df[df['filename'].str.contains(filename)]\n",
    "            if not row.empty:\n",
    "                grp = row['grp'].values[0]\n",
    "                label = 0 if '/benign/' in image_path else 1\n",
    "                train_test = 0 if grp == 'train' else 1\n",
    "                triplets.append((img_path, label, train_test))\n",
    "        self.data = np.array(triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label, train_set = self.data[idx]\n",
    "        image = read_image(img_path)\n",
    "        image = image.float() / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, train_set\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a1237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b250a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['filename'] = df['filename'].str.replace('BreaKHis_v1/histology_slides/breast/', 'data/', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93490e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>mag</th>\n",
       "      <th>grp</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "      <td>data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  mag    grp                                           filename\n",
       "0     1  100  train  data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...\n",
       "1     1  100  train  data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...\n",
       "2     1  100  train  data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...\n",
       "3     1  100  train  data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10...\n",
       "4     1  100  train  data/benign/SOB/adenosis/SOB_B_A_14-22549AB/10..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f71bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all image path\n",
    "breast_img_paths = glob.glob('data/**/*.png', recursive = True)\n",
    "# Keep only the ones with selected magnification\n",
    "filtered_img_paths = []\n",
    "for img in breast_img_paths:\n",
    "    img_name = Path(img).name\n",
    "    for mag in [40, 100]:\n",
    "        if f\"-{mag}-\" in img_name:\n",
    "            filtered_img_paths.append(img) \n",
    "triplets = []\n",
    "\n",
    "for image_path in filtered_img_paths:\n",
    "    filename = Path(image_path).name\n",
    "    row = df[df['filename'].str.contains(filename)]\n",
    "    if not row.empty:\n",
    "        grp = row['grp'].values[0]\n",
    "        label = 0 if '/benign/' in image_path else 1\n",
    "        train_test = 0 if grp == 'train' else 1\n",
    "        triplets.append((img_path, label, train_test))\n",
    "triplets = np.array(triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7759bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4de8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BreakHisDataset(\n",
    "    data_folder_path='data/', \n",
    "    magnification=[40, 100],\n",
    "    transform=transform_pipeline,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = BreakHisDataset(\n",
    "    data_folder_path='data/', \n",
    "    magnification=[40, 100],\n",
    "    transform=transform_pipeline, \n",
    "    train=False\n",
    ")\n",
    "\n",
    "# 2. Create the DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,      # Always shuffle training data\n",
    "    num_workers=4      # Parallel data loading\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False,     # No need to shuffle test data\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabd1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dldiy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
